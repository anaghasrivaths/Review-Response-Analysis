{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import jsonlines\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from argparse import ArgumentParser\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from LocalSettings import chromedriver_path, DataLocation\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "\n",
    "\n",
    "# arguments\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument('-f', '--file', type=str, help='Output file name.')\n",
    "parser.add_argument('-b', '--begin', type=int, default=0, help='Beginning file index number.')\n",
    "parser.add_argument('-e', '--end', type=int, help='Number of Pages to parse.')\n",
    "parser.add_argument('-o', '--overwrite', type=str, help='Pass \"a\" to append or \"w\" to overwrite an existing file.')\n",
    "parser.add_argument('--first_pages', action='store_true')\n",
    "args = parser.parse_args()\n",
    "\n",
    "if not args.file:\n",
    "    raise Exception(\n",
    "        'Output file name not provided. use -f to specify your file name.')\n",
    "\n",
    "if not args.overwrite and args.file in os.listdir('Outputs'):\n",
    "    raise Exception(\n",
    "        f'{args.file} already exists. use \"-o a\" to append. use \"-o w\" to overwrite.')\n",
    "\n",
    "elif not args.overwrite:\n",
    "    args.overwrite = 'w'\n",
    "\n",
    "if not args.end:\n",
    "    args.end = args.begin+50000\n",
    "\n",
    "# chrome driver settings\n",
    "topics_xpath = \"//div[@class='XUVJZtom'][@data-test-target='expand-review']\"\n",
    "options = Options()\n",
    "options.add_argument(\"--disable-infobars\")\n",
    "options.add_argument('--headless')\n",
    "browser = webdriver.Chrome(executable_path=chromedriver_path, options=options)\n",
    "\n",
    "\n",
    "def get_page(webpage: str):\n",
    "    \"\"\" parse webpage \"\"\"\n",
    "\n",
    "    soup = BeautifulSoup(webpage, 'lxml')\n",
    "    return soup\n",
    "\n",
    "\n",
    "def hotel_name(soup):\n",
    "    \"\"\" get hotel names and address from All hotel pages \"\"\"\n",
    "\n",
    "    try:\n",
    "        return soup.find(\"h1\", id='HEADING').text\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def hotel_address(soup):\n",
    "    \"\"\" get hotel address \"\"\"\n",
    "\n",
    "    try:\n",
    "        return soup.find('span', {'class': '_3ErVArsu jke2_wbp'}).text\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def count_reviews(soup):\n",
    "    \"\"\" Hotel Total Number of Reviews \"\"\"\n",
    "\n",
    "    try:\n",
    "        return int(soup.find('span', {'class': '_33O9dg0j'}).text.replace(' reviews', ''))\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def review_pages(soup):\n",
    "    \"\"\" Find/Create All Review Pages Available (The number of Pages Depends on the Number of Reviews) \"\"\"\n",
    "\n",
    "    try:\n",
    "        all_links = soup.find_all('a', {'class': 'pageNum'})\n",
    "        hyperlink = []\n",
    "        for line in all_links:\n",
    "            AdditionalPagesInfo = {'hyperlink': line['href'],\n",
    "                                   'pageNum': int(line.text)}\n",
    "            hyperlink.append(AdditionalPagesInfo)\n",
    "        available_links = pd.DataFrame(hyperlink)\n",
    "        page_number_list = available_links.pageNum.tolist()\n",
    "        ReviewLinks = available_links.hyperlink.tolist()\n",
    "        if len(page_number_list) > 1:\n",
    "            if page_number_list[-1] - page_number_list[-2] > 1:\n",
    "                regex = r\"Reviews\\-or\\d+\"\n",
    "                template_link = available_links.iloc[0, 0]\n",
    "                # missing_pages_count = page_number_list[-1] - page_number_list[-2]\n",
    "                for i in range(page_number_list[-2]*5, (page_number_list[-1]-1)*5, 5):\n",
    "                    ReviewLinks.append(re.sub(regex, f'Reviews-or{i}', template_link))\n",
    "                return ReviewLinks\n",
    "            else:\n",
    "                return ReviewLinks\n",
    "        else:\n",
    "            return ReviewLinks\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Extract Reviews and the information of the reviewers\n",
    "def review_box(soup):\n",
    "    \"\"\" Review Box: each page has a maximum of 5 boxes \"\"\"\n",
    "\n",
    "    try:\n",
    "        return soup.find_all('div', {'class': '_2wrUUKlw _3hFEdNs8'})\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def reviewer_name(box) -> str:\n",
    "    \"\"\" Reviewer Name and Profile \"\"\"\n",
    "\n",
    "    try:\n",
    "        return box.find('a', {'class': 'ui_header_link _1r_My98y'}).text\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def reviewer_profile(box) -> str:\n",
    "    \"\"\" link to reviewer profile \"\"\"\n",
    "\n",
    "    try:\n",
    "        return box.find('a', {'class': 'ui_header_link _1r_My98y'})['href']\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def review_id(box) -> int:\n",
    "    \"\"\" unique review id \"\"\"\n",
    "\n",
    "    try:\n",
    "        return box.find('div', {'class': 'oETBfkHU'})['data-reviewid']\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def review_date(box) -> str:\n",
    "    \"\"\" date of the review \"\"\"\n",
    "\n",
    "    try:\n",
    "        return box.find('div', {'class': '_2fxQ4TOx'}).text.replace(reviewer_name(box)+' wrote a review ', '')\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def reviewer_location(box):\n",
    "    \"\"\" Location of the Reviewer \"\"\"\n",
    "\n",
    "    try:\n",
    "        return box.find('span', {'class': 'default _3J15flPT small'}).text\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def reviewer_contribution(box) -> int:\n",
    "    \"\"\" Reviewers Total Contribution \"\"\"\n",
    "\n",
    "    try:\n",
    "        regex = r'contributions?'\n",
    "        contributions = box(text=re.compile(regex))[0].parent.text\n",
    "        return int(re.sub(regex, '', contributions))\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def review_helpful_votes(box) -> int:\n",
    "    \"\"\" Review Helpful Votes \"\"\"\n",
    "\n",
    "    try:\n",
    "        regex = r'helpful votes?'\n",
    "        Votes = box(text=re.compile(regex))[0].parent.text\n",
    "        return int(re.sub(regex, '', Votes))\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def review_star(box):\n",
    "    \"\"\" Number of Stars provided to hotel by the reviewer \"\"\"\n",
    "\n",
    "    try:\n",
    "        regex = r'ui\\_bubble\\_rating bubble\\_\\d+'\n",
    "        match = re.findall(regex, str(box))[0]\n",
    "        score = int(re.findall(r'\\d+', match)[0])\n",
    "        return score\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def review_text(box):\n",
    "    \"\"\" The text of the review \"\"\"\n",
    "\n",
    "    try:\n",
    "        return box.find('q', {'class': 'IRsGHoPm'}).text\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def date_of_stay(box):\n",
    "    \"\"\" Date of Stay \"\"\"\n",
    "\n",
    "    try:\n",
    "        return box.find('span', {'class': '_34Xs-BQm'}).text.strip().replace('Date of stay: ', '')\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "# Trip Type\n",
    "def trip_type(box):\n",
    "    try:\n",
    "        return box.find('span', {'class': '_2bVY3aT5'}).text.strip().replace('Trip type: ', '')\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "def ratings_detail(box):\n",
    "    \"\"\" Rating Details in the Review \"\"\"\n",
    "\n",
    "    Rating_values = {}\n",
    "    try:\n",
    "        RatingDetails = box.find_all('div', {'class': '_3ErKuh24 _1OrVnQ-J'})\n",
    "        for Rating in RatingDetails:\n",
    "            Rating_values[f'{Rating.text}Score'] = review_star(Rating)\n",
    "        return Rating_values\n",
    "    except:\n",
    "        return Rating_values\n",
    "\n",
    "\n",
    "def response_details(box):\n",
    "    \"\"\" Response of the Hotel \"\"\"\n",
    "\n",
    "    try:\n",
    "        # ResponseBox = box.find('div', {'class': 'XPYR1502'})\n",
    "        ResponseInfo = {'ResponderName': box.find('div', {'class': '_204cKjWJ'}).text,\n",
    "                        'ResponseDate': box.find('div', {'class': '_2lY-Jowi'})['title'],\n",
    "                        'ResponseText': box.find('span', {'class': 'sT5TMxg3'}).text}\n",
    "        return ResponseInfo\n",
    "    except:\n",
    "        return {'ResponderName': None,\n",
    "                'ResponseDate': None,\n",
    "                'ResponseText': None}\n",
    "\n",
    "\n",
    "def scrape_additional_pages():\n",
    "    New_Review_linksPD = pd.read_csv('Outputs/Additional_Review_Pages.csv', names=['link'])\n",
    "    ReviewPageList = New_Review_linksPD.link.tolist()\n",
    "    ReviewPageList.sort()\n",
    "    ScrapeList = ReviewPageList[args.begin: args.end]\n",
    "    with jsonlines.open(f'Outputs/{args.file}', args.overwrite) as destination:\n",
    "        for link in tqdm(ScrapeList):\n",
    "            try:\n",
    "                browser.get(link)\n",
    "                browser.execute_script(\"arguments[0].scrollIntoView(false);\",\n",
    "                                       browser.find_element_by_xpath(topics_xpath))\n",
    "                WebDriverWait(browser, 10).until(\n",
    "                    expected_conditions.visibility_of_any_elements_located((By.XPATH, topics_xpath)))\n",
    "                # ReadMore = browser.find_element_by_xpath(topics_xpath)\n",
    "                ReadMore = WebDriverWait(browser, 10).until(\n",
    "                    expected_conditions.element_to_be_clickable((By.XPATH, topics_xpath)))\n",
    "                ReadMore.click()\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            html = browser.page_source\n",
    "            WholePage = get_page(html)\n",
    "            ReviewBoxes = review_box(WholePage)\n",
    "            for each in ReviewBoxes:\n",
    "                ReviewInformation = {'link': link,\n",
    "                                     'HotelName': hotel_name(WholePage),\n",
    "                                     'HotelAddress': hotel_address(WholePage),\n",
    "                                     'CountReviews': count_reviews(WholePage),\n",
    "                                     'ReviewerName': reviewer_name(each),\n",
    "                                     'ReviewerProfile': reviewer_profile(each),\n",
    "                                     'ReviewID': review_id(each),\n",
    "                                     'ReviewDate': review_date(each),\n",
    "                                     'ReviewerLocation': reviewer_location(each),\n",
    "                                     'ReviewerContribution': reviewer_contribution(each),\n",
    "                                     'ReviewHelpfulVotes': review_helpful_votes(each),\n",
    "                                     'ReviewStar': review_star(each),\n",
    "                                     'ReviewText': review_text(each),\n",
    "                                     'DateOfStay': date_of_stay(each),\n",
    "                                     'TripType': trip_type(each),\n",
    "                                     'RatingsDetail': ratings_detail(each),\n",
    "                                     'ResponseDetails': response_details(each)}\n",
    "                destination.write(ReviewInformation)\n",
    "    browser.quit()\n",
    "\n",
    "def scrape_first_pages():\n",
    "    New_Review_linksPD = pd.read_csv('Outputs/hotels_with_reviews.csv')\n",
    "    ReviewPageList = New_Review_linksPD.link.tolist()\n",
    "    ReviewPageList.sort()\n",
    "    ScrapeList = ReviewPageList[args.begin: args.end]\n",
    "    with jsonlines.open(f'Outputs/{args.file}', args.overwrite) as destination:\n",
    "        for link in tqdm(ScrapeList):\n",
    "            html = open(os.path.join(DataLocation, link), encoding='utf-8').read()\n",
    "            WholePage = get_page(html)\n",
    "            ReviewBoxes = review_box(WholePage)\n",
    "            for each in ReviewBoxes:\n",
    "                ReviewInformation = {'link': link,\n",
    "                                     'HotelName': hotel_name(WholePage),\n",
    "                                     'HotelAddress': hotel_address(WholePage),\n",
    "                                     'CountReviews': count_reviews(WholePage),\n",
    "                                     'ReviewerName': reviewer_name(each),\n",
    "                                     'ReviewerProfile': reviewer_profile(each),\n",
    "                                     'ReviewID': review_id(each),\n",
    "                                     'ReviewDate': review_date(each),\n",
    "                                     'ReviewerLocation': reviewer_location(each),\n",
    "                                     'ReviewerContribution': reviewer_contribution(each),\n",
    "                                     'ReviewHelpfulVotes': review_helpful_votes(each),\n",
    "                                     'ReviewStar': review_star(each),\n",
    "                                     'ReviewText': review_text(each),\n",
    "                                     'DateOfStay': date_of_stay(each),\n",
    "                                     'TripType': trip_type(each),\n",
    "                                     'RatingsDetail': ratings_detail(each),\n",
    "                                     'ResponseDetails': response_details(each)}\n",
    "                destination.write(ReviewInformation)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if not args.first_pages:\n",
    "        scrape_additional_pages()\n",
    "    else:\n",
    "        scrape_first_pages()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
